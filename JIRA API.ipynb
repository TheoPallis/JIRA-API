{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3166"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_colwidth = None\n",
    "# Set up folders and time variables\n",
    "tday = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "folder = r\"\\\\lawoffice\\GSLODocuments\\LegalServices_Division\\01.Lawoffice_Common\\BUSINESS ANALYSTS\\BI JIRA\\jira_app\"\n",
    "from jira_helper import jira_connect,format_date,extract_year,extract_month,minutes\n",
    "df = jira_connect()\n",
    "len(df)\n",
    "# df.sort_values(by='Issue Key',ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pallist\\Desktop\\Desktop\\ΤΡΕΧΟΝΤΑ\\Code November 2024\\Large Scripts\\jira_helper.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column+\"_date\"] = pd.to_datetime(df[column], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\pallist\\Desktop\\Desktop\\ΤΡΕΧΟΝΤΑ\\Code November 2024\\Large Scripts\\jira_helper.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column+\"_date\"] = pd.to_datetime(df[column], errors='coerce', dayfirst=True)\n",
      "C:\\Users\\pallist\\AppData\\Local\\Temp\\ipykernel_26408\\1800153737.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test['Εκκρεμή'] = np.where(test['Status'].isin(pending_list), \"Εκκρεμή\", \"Μη Εκκρεμή\")\n",
      "C:\\Users\\pallist\\AppData\\Local\\Temp\\ipykernel_26408\\1800153737.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test['RPA_Flag'] = np.where(df['Summary'].str.contains('rpa', case=False, na=False), 'RPA', 'No-RPA')\n",
      "C:\\Users\\pallist\\AppData\\Local\\Temp\\ipykernel_26408\\1800153737.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test['Iteration_Flag'] = np.where(df['Label'] == '#C.It', 'Iteration', 'No-Iteration')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Issue Key   \n",
      "0  DNY-3236  \\\n",
      "1  DNY-3235   \n",
      "2  DNY-3234   \n",
      "3  DNY-3233   \n",
      "4  DNY-3232   \n",
      "\n",
      "                                                                    Summary   \n",
      "0                                       DNY - 2870 Do Value Άμεσοι έλεγχοι   \\\n",
      "1                                  ΠΡΟΣΘΗΚΗ ΥΠΟΘΕΣΕΩΝ ΣΤΗΝ ΑΝΑΦΟΡΑ ΑΙΤ-3387   \n",
      "2                                  Επανέλεγχοι για προσημείωση, απο Κομίλη.   \n",
      "3                           Μαζική εισαγωγή πληρωμών (κτηματολόγιο) στο CMS   \n",
      "4  Ενημέρωση mappings RPA Επιταγών Α Πειραιώς και λεκτικού επιταγής Εθνικής   \n",
      "\n",
      "   Reporter      Assignee    Status                       Created   \n",
      "0    Πανίκα        Κοσμής      Open  2024-12-11T12:51:54.858+0200  \\\n",
      "1  Κανναβού        Βούρας      Open  2024-12-11T12:50:50.018+0200   \n",
      "2   Μποζώνη       Μποζώνη  Resolved  2024-12-11T12:48:04.589+0200   \n",
      "3    Πανίκα       Ρούσσου      Open  2024-12-11T12:05:44.908+0200   \n",
      "4    Πάλλης  Παπαδόπουλος      Open  2024-12-11T11:55:11.423+0200   \n",
      "\n",
      "           Updated      Resolved     Label     Estimate  ... Log Work.94   \n",
      "0  No Updated Date  Not Resolved  No Label  No Estimate  ...     No Data  \\\n",
      "1  No Updated Date  Not Resolved  No Label  No Estimate  ...     No Data   \n",
      "2  No Updated Date  Not Resolved  No Label  No Estimate  ...     No Data   \n",
      "3  No Updated Date  Not Resolved  No Label  No Estimate  ...     No Data   \n",
      "4  No Updated Date  Not Resolved  No Label  No Estimate  ...     No Data   \n",
      "\n",
      "  Log Work.95 Log Work.96 Log Work.97 Log Work.98 Company DNY_Assignee   \n",
      "0     No Data     No Data     No Data     No Data     DNY           IT  \\\n",
      "1     No Data     No Data     No Data     No Data     DNY           IT   \n",
      "2     No Data     No Data     No Data     No Data      IT           IT   \n",
      "3     No Data     No Data     No Data     No Data     DNY           IT   \n",
      "4     No Data     No Data     No Data     No Data     DNY           IT   \n",
      "\n",
      "  Department                      Created_date Resolved_date  \n",
      "0  Δικηγόροι  2024-11-12 12:51:54.858000+02:00           NaT  \n",
      "1  Αναθέσεις  2024-11-12 12:50:50.018000+02:00           NaT  \n",
      "2         IT  2024-11-12 12:48:04.589000+02:00           NaT  \n",
      "3  Δικηγόροι  2024-11-12 12:05:44.908000+02:00           NaT  \n",
      "4        BAs  2024-11-12 11:55:11.423000+02:00           NaT  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#C.It\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo-Iteration\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# test.to_excel(os.path.join(folder,'test.xlsx'))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# os.startfile('test.xlsx')\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#  # 4) Υπολογισμός Αρχικής Εκτίμησης\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEstimate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3600\u001b[39;49m\n\u001b[0;32m     34\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;28mround\u001b[39m(x,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Get the non log columns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6108\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6107\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:178\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pallist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:135\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    132\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 135\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    138\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "mapping_file = r\"\\\\lawoffice\\GSLODocuments\\LegalServices_Division\\01.Lawoffice_Common\\BUSINESS ANALYSTS\\BI JIRA\\mapping names jira.xlsx\"\n",
    "mapping_df = pd.read_excel(mapping_file)\n",
    "mapping_dict = mapping_df.set_index('Raw')['Cleaned'].to_dict()\n",
    "dept_dict = mapping_df.set_index('Raw')['Department'].to_dict()\n",
    "company_dict = mapping_df.set_index('Raw')['Company'].to_dict() \n",
    "\n",
    "df['Company'] = df['Reporter'].map(company_dict)\n",
    "df['DNY_Assignee'] = df['Assignee'].map(company_dict)\n",
    "df['Department'] = df['Reporter'].map(dept_dict)\n",
    "df= df.replace(mapping_dict)\n",
    "df['Assignee'] = np.where((df['Assignee'].astype(str) == '0') & (df['Reporter'] == 'Βαγιάννης'), 'Βαγιάννης', \n",
    "                 np.where((df['Assignee'].astype(str) == '0') & (df['Reporter'] == 'Παπαδόπουλος'), 'Παπαδόπουλος', df['Assignee']))\n",
    "\n",
    "test = df\n",
    "# test = test.dropna(subset='Issue key') @extra dupes1\n",
    "# # Replace null values with 0\n",
    "test.fillna(0, inplace=True)\n",
    "# # 1) Μετατροπή ημερομηνίας σε date format (απαιτεί και την ρύθμιση ως ημερομηνίας εντός του bi)\n",
    "format_date('Created',test)\n",
    "# format_date('Updated',test)\n",
    "format_date('Resolved',test)\n",
    "print(test.head())\n",
    "# # 2) Ομαδοποίηση Status σε κατηγορίες Εκκρεμή και Μη Εκκρεμή\n",
    "pending_list = ['Open', 'In Progress', 'Approved', 'For Approval', 'Specification Analysis','Reopened']\n",
    "test['Εκκρεμή'] = np.where(test['Status'].isin(pending_list), \"Εκκρεμή\", \"Μη Εκκρεμή\")\n",
    "# # 3) Rpa and Iteration Flag\n",
    "test['RPA_Flag'] = np.where(df['Summary'].str.contains('rpa', case=False, na=False), 'RPA', 'No-RPA')\n",
    "test['Iteration_Flag'] = np.where(df['Label'] == '#C.It', 'Iteration', 'No-Iteration')\n",
    "\n",
    "# test.to_excel(os.path.join(folder,'test.xlsx'))\n",
    "# os.startfile('test.xlsx')\n",
    "#  # 4) Υπολογισμός Αρχικής Εκτίμησης\n",
    "test['Estimate'] = test['Estimate'] / 3600\n",
    "test['Estimate'] = test['Estimate'].astype(float).apply(lambda x : round(x,2))\n",
    "\n",
    "\n",
    "# Get the non log columns\n",
    "cols = ['Issue Key',\n",
    "       'Summary',\n",
    "       'Status',\n",
    "       'Created',\n",
    "       'Resolved',\n",
    "       'Assignee',\n",
    "       'Reporter',\n",
    "       'Updated_date',\n",
    "       'Created_date',\n",
    "       'Resolved_date',\n",
    "       'Original estimate',\n",
    "       'RPA_Flag',\n",
    "       'Iteration_Flag',\n",
    "       'Εκκρεμή',\n",
    "       'Estimate',\n",
    "       'Company',\n",
    "       'DNY_Assignee',\n",
    "       'Department']\n",
    "\n",
    "# Get the log columns\n",
    "log_cols = [f'Log Work.{i}' if i > 0 else 'Log Work' for i in range(99)]\n",
    "hours_cols = ['Issue Key', 'hours_assignee','before','during','after','Most_recent_update','Log_Month','Log_Year']# 'Time_before_resolved', 'Time_in_resolved','Time_after_resolved',\n",
    "\n",
    "\n",
    "def melt_df(df) :\n",
    "    melted = pd.melt(df,id_vars=cols,value_vars=log_cols,value_name='Logs')\n",
    "    melted['Updated_Month'] = melted['Updated_date'].dt.month.astype(str)\n",
    "    melted['Updated_date'] = pd.to_datetime(melted['Updated_date'], errors='coerce')\n",
    "    melted['Log_Month'] = melted['Logs'].apply(extract_month).fillna(\"0\")\n",
    "    melted['Log_Year'] = melted['Logs'].apply(extract_year).fillna(\"0\")\n",
    "    melted['Log_Year'] = melted['Logs'].apply(extract_year)\n",
    "    melted['Resolved_Month'] = melted['Resolved'].apply(extract_month)\n",
    "    melted['Resolved_Year'] = melted['Resolved'].apply(extract_year)\n",
    "    melted['minutes_assignee'] = melted['Logs'].apply(minutes)\n",
    "    melted['minutes_assignee'] = melted['minutes_assignee'].fillna(0).astype(int)\n",
    "    melted['hours'] = melted['minutes_assignee']  / 3600\n",
    "    melted['hours'] = melted['hours'].astype(float).round(2)\n",
    "    before = (melted['Log_Month'] < melted['Resolved_Month']) & (melted['Log_Year'] <= melted['Resolved_Year']) & (melted['Status'].isin(['Resolved','Closed']))\n",
    "    during = (melted['Log_Month'] == melted['Resolved_Month']) & (melted['Log_Year'] == melted['Resolved_Year']) & melted['Status'].isin(['Resolved','Closed'])\n",
    "    after = (melted['Log_Month'] > melted['Resolved_Month']) &  (melted['Log_Year'] >= melted['Resolved_Year']) &melted['Status'].isin(['Resolved','Closed'])\n",
    "    # Calculate time spent before the resolution month, handling missing values\n",
    "    melted['Time_before_resolved'] = melted[before].groupby('Issue key')['hours'].transform('sum').fillna(0)\n",
    "    # Calculate time spent in the resolved month, handling missing values\n",
    "    melted['Time_in_resolved'] = melted[during].groupby('Issue key')['hours'].transform('sum').fillna(0)\n",
    "    # Calculate time spent after the resolution month\n",
    "    melted['Time_after_resolved'] = melted[after].groupby('Issue key')['hours'].transform('sum').fillna(0)\n",
    "    # Calculate the total hours spent on the issue by assignee\n",
    "    melted['hours_assignee'] = melted.groupby('Issue key')['hours'].transform('sum')\n",
    "    return melted\n",
    "\n",
    "\n",
    "# print(\"Unpivoting df\")\n",
    "# # # Unpivot to get logs as rows\n",
    "hours_df = melt_df(test)\n",
    "# print(\"Unpivoted df\")\n",
    "hours_df['before'] = hours_df.groupby('Issue Key')['Time_before_resolved'].transform('min')\n",
    "hours_df['after'] = hours_df.groupby('Issue Key')['Time_after_resolved'].transform('min')\n",
    "hours_df['during'] = hours_df.groupby('Issue Key')['Time_in_resolved'].transform('min')\n",
    "hours_df['Most_recent_update'] = hours_df.groupby('Issue key')['Updated_date'].transform('max')\n",
    "hours_df['Most_recent_update'] = pd.to_datetime(hours_df['Most_recent_update'],format='%d/%m/%Y',errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "# # hours_df = hours_df.drop_duplicates() @extra dupes2\n",
    "hours_df.to_excel(os.path.join(folder,'hours_df.xlsx'))\n",
    "os.startfile('hours_df.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hours_df = hours_df.drop_duplicates(subset='Issue key')\n",
    "# hours_df = hours_df[hours_cols]\n",
    "# test = test[cols]\n",
    "# merged_df = pd.merge(hours_df,test,on='Issue key',how='inner')\n",
    "# print(\"Merged df\")\n",
    "# merged_df['Απόκλιση'] = merged_df['hours_assignee'] - merged_df['Estimate'] #processing\n",
    "# # merged_df['Απόκλιση'] = merged_df['Απόκλιση'].apply(lambda x : round(x,2)) \n",
    "# merged_df['Εντός Εκτίμησης'] = np.where(merged_df['Απόκλιση'] <= 0, 'Εντός Εκτίμησης', 'Εκτός Εκτίμησης')#processing\n",
    "# merged_df['Εντός Εκτίμησης'] = np.where(merged_df['Estimate'] == 0, 'Δεν έχει δοθεί εκτίμηση', merged_df['Εντός Εκτίμησης'])#processing\n",
    "# merged_df['Created_Resolved_days'] = np.where(\n",
    "#     (merged_df['Status'] == 'Resolved') | (merged_df['Status'] == 'Closed'),\n",
    "#     (merged_df['Resolved_date'] - merged_df['Created_date']).dt.days,\n",
    "#     np.nan)\n",
    "# today = pd.Timestamp(datetime.today())\n",
    "# merged_df['Created_vs_Today_Days'] = (today - merged_df['Created_date']).dt.days\n",
    "# merged_df['Key'] = merged_df['Issue key'].str.strip(\"DNY-\").astype(int)\n",
    "# merged_df['Created_Today'] = np.where((merged_df['Created_date'].dt.date == today.date()) & (merged_df['Created_date'].dt.year == today.year), 'Yes', 'No')\n",
    "# merged_df['Created_Current_Week'] = np.where((merged_df['Created_date'].dt.isocalendar().week == today.isocalendar().week) & (merged_df['Created_date'].dt.year == today.year), 'Yes', 'No')\n",
    "# merged_df['Created_Last_Week'] = np.where(merged_df['Created_date'].dt.isocalendar().week == (today.isocalendar().week - 1), 'Yes', 'No')\n",
    "# merged_df['Created_Current_Month'] = np.where((merged_df['Created_date'].dt.month == today.month) & (merged_df['Created_date'].dt.year == today.year), 'Yes', 'No')\n",
    "# merged_df['Resolved_Today'] = np.where((merged_df['Resolved_date'].dt.date == today.date()) & (merged_df['Resolved_date'].dt.year == today.year), 'Yes', 'No')\n",
    "# merged_df['Resolved_Current_Week'] = np.where((merged_df['Resolved_date'].dt.isocalendar().week == today.isocalendar().week) & (merged_df['Resolved_date'].dt.year == today.year), 'Yes', 'No')\n",
    "# merged_df['Resolved_Last_Week'] = np.where(merged_df['Resolved_date'].notna() & (merged_df['Resolved_date'].dt.isocalendar().week == (today.isocalendar().week - 1)), 'Yes', 'No')\n",
    "# merged_df['Resolved_Current_Month'] = np.where((merged_df['Resolved_date'].dt.month == today.month) & (merged_df['Resolved_date'].dt.year == today.year), 'Yes', 'No')\n",
    "# merged_df['Week_Resolved'] = merged_df['Resolved_date'].dt.isocalendar().week\n",
    "# merged_df['Week_Created'] = merged_df['Created_date'].dt.isocalendar().week\n",
    "\n",
    "# delete_old_files(folder)\n",
    "# merged_df.to_excel(os.path.join(folder,'data_for_bi.xlsx'))\n",
    "# # os.startfile(os.path.join(folder,'data_for_bi.xlsx'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import openpyxl\n",
    "# from openpyxl import load_workbook\n",
    "# from openpyxl.styles import Font, PatternFill, Alignment\n",
    "\n",
    "# def format_df(file) :\n",
    "#     workbook = openpyxl.load_workbook(file)\n",
    "#     for worksheet in workbook:\n",
    "#         font = Font(color='FFFFFF', bold=True)\n",
    "#         fill = PatternFill(start_color='5552A2', end_color='5552A2', fill_type='solid')\n",
    "#         alignment = Alignment(horizontal='left')  # Left align\n",
    "#         for cell in worksheet[1]:\n",
    "#             cell.font = font\n",
    "#             cell.fill = fill\n",
    "#             cell.alignment = alignment\n",
    "#         for column in worksheet.columns:\n",
    "#             worksheet.column_dimensions[openpyxl.utils.get_column_letter(column[0].column)].width = 40      \n",
    "\n",
    "#     workbook.save(file)\n",
    "\n",
    "# clean_df = merged_df\n",
    "# clean_df.rename(columns={'before': 'Hours_Spent_Before_Month_of_Resolution', \n",
    "#                          'during': 'Hours_Spent_In_Month_of_Resolution',\n",
    "#                          'after' : 'Hours_Spent_After_Month_Of_Resolution',\n",
    "#                          'Created_Resolved_days': 'Days_Between_Creation_and_Resolution',\n",
    "#                          'Created_vs_Today_Days': 'Days_Since_Creation',\n",
    "#                          'Απόκλιση': 'Hour_Difference_From_Estimate',\n",
    "#                          'hours_assignee': 'Total_Hours_Spent',                         \n",
    "#                          }, inplace=True)\n",
    "\n",
    "# # clean_df.drop(columns=['Original estimate','Updated_date','Created','Resolved'], inplace=True)\n",
    "# clean_df.sort_values(by='Key',inplace=True)\n",
    "# clean_df['Resolved_date'] = pd.to_datetime(clean_df['Resolved_date'],format='%d/%m/%Y',errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "# clean_df['Created_date'] = pd.to_datetime(clean_df['Created_date'],format='%d/%m/%Y',errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "# clean_df['Most_recent_update'] = pd.to_datetime(clean_df['Most_recent_update'],format='%d/%m/%Y',errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "# clean_df.to_excel(os.path.join(folder,'Excel_Report_Jira.xlsx'),index=False)\n",
    "# format_df(os.path.join(folder,'Excel_Report_Jira.xlsx'))\n",
    "# os.startfile(os.path.join(folder,'Excel_Report_Jira.xlsx'))\n",
    "# end_time = datetime.now()\n",
    "# print(f\"Operation complete : {start_time.strftime('%H:%M:%S')} - {end_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
